\section{Introduction}

The APGAS programming model~\cite{amp10}---Asynchronous Partitioned Global Address Space---is simple but powerful
model of concurrency and distribution. It combines PGAS with asynchrony.
In (A)PGAS the computation and data in an application are logically partitioned into places.
In APGAS the computation is further organized into lightweight asynchronous tasks.
With these, APGAS can express both
regular and irregular parallelism, message-passing-style and
active-message-style computations, fork-join and bulk-synchronous
parallelism.  In contrast to hybrid models like MPI+OpenMP, the same
constructs underpin both intra- and inter-place concurrency.

The X10 programming language~\cite{oopsla05} augments a familiar imperative, strongly-typed, garbage-collected, object-oriented language with the APGAS model. X10 is implemented with two backends. On the managed backend, X10
compiles into Java and runs on a cluster of JVMs. On the native backend, X10 compiles into C++ and generates a native binary
for execution on scale-out systems.
X10, and by extension
\apgas, has been used successfully to implement distributed applications
running across tens of thousands of cores~\cite{TardieuETAL14X10ApgasAtPetascale}.

TODO

Current state requires programmers interested in the \apgas model to buy in the
X10 language and development platform, which may not be possible for an array
of reasons.

To expose more programmers, we believe in the approach of exposing the critical
components of \apgas as a library. Particularly suitable for Scala, a language
that is welcoming of library-based extensions, and that has been a pioneer on
the JVM for alternative concurrency paradigms. Notably, the original actor
library and its more recent successor Akka are examples of both. Our work is
based on a recent implementation of \apgas in Java \cite{APGASJava}, reworked to
fit Scala idioms.

We hope that people will embrace \apgas, either as a substitute for or as a
complement to other concurrency libraries. Examples throughout the paper are
verbatim Scala/\apgas code. X10 shares ancestry/inspiration with Scala, and the
facilities in Scala for library-defined language extensions makes the code look
almost exactly like X10 programs.

\subsection{Overview of the \apgas Programming Model}

A {\em place} is an abstraction of mutable, shared-memory region and worker threads operating on this memory.
A single application typically runs over a collection of places. In this work, each place is implemented as a separate JVM.

A {\em task} is an abstraction of a sequence of computations. In this work, a task is specified as a block.
Each task is bound to a particular place. 
A task can spawn local and remote tasks, i.e., tasks to be executed in the same place or elsewhere.

A local task shares the heap of the parent task. A remote task executes on a snapshot of the parent task's heap captured when the task is spawned. A task can instantiate \emph{global references} to objects in its heap to work around the capture semantics.
Global references are copied as part of the snapshot but not the target objects. A global reference can only be dereferenced
at the place of the target object where it resolves to the original object.

A task can wait for the termination of all the tasks transitively spawned from it.
Thanks to global references, remote tasks, and termination control,
a task can indirectly manipulate remote objects.

The two fundamental control structures in APGAS are
 \lstinline{asyncAt}, and \lstinline{finish}, whose signatures in
the Scala implementation are:
\begin{lstlisting}
  def asyncAt(place: Place)(body: $\RA$Unit) : Unit
  def finish(body : $\RA$Unit) : Unit
\end{lstlisting}
As is common in Scala libraries, we use by-name arguments to capture blocks.

The \lstinline{async} construct spawns an asynchronous task at place \lstinline{p} and returns
immediately. It is therefore the primitive construct for both \emph{concurrency} and \emph{distribution}.
The \lstinline{finish} construct detects termination: an invocation of
\lstinline{finish} will execute its body and block until all nested invocations
of \lstinline{asyncAt} have completed. The set of \lstinline{asyncAt} invocations
that are controlled includes all recursive invocations, including all remote
ones. This makes \lstinline{finish} a powerful contribution of \apgas.

Because spawning local tasks is so common, we have an optimized version of \lstinline{asyncAt} for this purpose with signature:
\begin{lstlisting}
  def async(body: $\RA$Unit) : Unit
\end{lstlisting}  

TODO

\begin{lstlisting}
  def at[T:Serialization](place: Place)(body: $\RA$T) : T
\end{lstlisting}
We discuss the \lstinline{Serialization} type class in
Section~\ref{sec:serialization}.


The primitive construct for \emph{distribution} is \lstinline{at}. The invocation
\begin{lstlisting}
  val r = at(p) { work() }
\end{lstlisting}
executes the method \lstinline{work} at place \lstinline{p}, and blocks until
it terminates and returns the result. Asynchronously spawning tasks at remote places can be achieved by composing the two constructs:
\begin{lstlisting}
  at(p) { async { work() }}
\end{lstlisting}
This operation is so common that we have an semantically equivalent but optimized version with the signature
\begin{lstlisting}
  def asyncAt(place: Place)(body: $\RA$Unit) : Unit
\end{lstlisting}

Finally, \lstinline{finish} detects termination: an invocation of
\lstinline{finish} will execute its body and block until all nested invocations
of \lstinline{async} have completed. The set of \lstinline{async} invocations
that are controlled includes all recursive invocations, including all remote
ones. This makes \lstinline{finish} a powerful contribution of \apgas.

Fibonacci

SPDM

Memory: PlaceLocal, PlaceLocalRef

Place failure.

\subsection{Similarities and Differences with Futures and Actors}

Discuss future vs.\ async (returning void means no value). Future can be awaited anywhere, but must be awaited ``manually''.

finish counts (including distributed tasks!) and has no real equivalent.

Actors: unified model for concurrency and distribution.

Handling failures: Try vs Exception vs. Messages

Async at: active messages: get executed "immediately", actor messages handled one-by-one.

In the following sections, we highlight some of the points above through two
benchmarks, \kmeans clustering and unbalanced tree search.


% \input{patterns}
% Figure~\ref{fig:apgas-patterns} shows patterns.
