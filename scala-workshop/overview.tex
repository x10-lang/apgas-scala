\section{Overview of \apgas in Scala}
\label{sec:apgas}

A {\em place} is an abstraction of a mutable, shared-memory region and worker threads operating on this memory.
A single application typically runs over a collection of places. In this work, each place is implemented as a separate JVM.

A {\em task} is an abstraction of a sequence of computations. In this work, a task is specified as a block.
Each task is bound to a particular place. 
A task can spawn local and remote tasks, i.e., tasks to be executed in the same place or elsewhere.

A local task shares the heap of the parent task. A remote task executes on a snapshot of the parent task's heap captured when the task is spawned. A task can instantiate \emph{global references} to objects in its heap to work around the capture semantics.
Global references are copied as part of the snapshot but not the target objects. A global reference can only be dereferenced
at the place of the target object where it resolves to the original object.
% FIXME how does one describe GlobalRef.forPlaces in these words?

A task can wait for the termination of all the tasks transitively spawned from it.
Thanks to global references, remote tasks, and termination control,
a task can indirectly manipulate remote objects.

The two fundamental control structures in APGAS are
 \lstinline{asyncAt}, and \lstinline{finish}, whose signatures in
the Scala implementation are:
\begin{lstlisting}
  def asyncAt(place: Place)(body: $\RA$Unit) : Unit
  def finish(body: $\RA$Unit) : Unit
\end{lstlisting}
As is common in Scala libraries, we use by-name arguments to capture blocks.

The \lstinline{async} construct spawns an asynchronous task at place \lstinline{p} and returns
immediately. It is therefore the primitive construct for both \emph{concurrency} and \emph{distribution}.
The \lstinline{finish} construct detects termination: an invocation of
\lstinline{finish} will execute its body and block until all nested invocations
of \lstinline{asyncAt} have completed. The set of \lstinline{asyncAt} invocations
that are controlled includes all recursive invocations, including all remote
ones. This makes \lstinline{finish} a powerful contribution of \apgas.

Because spawning local tasks is so common, we have an optimized version of
\lstinline{asyncAt} for this purpose with the signature:
\begin{lstlisting}
  def async(body: $\RA$Unit) : Unit
\end{lstlisting}
We can use \lstinline{async} for local concurrency. For instance, a parallel
version of Fibonacci sequence computation can be expressed as:
\begin{lstlisting}
  def fib(i: Int) : Long = if(i $\SLE$ 1) i else {
    var a, b: Long = 0L
    finish {
      async { a = fib(i - 2) }
      b = fib(i - 1)
    }
    a + b
  }
\end{lstlisting}
In the code above, each recursive invocation of \lstinline{fib} spawns an
additional, asynchronous, task, and \lstinline{finish} blocks until all
recursive dependencies have been computed.

\begin{lstlisting}
  def at[T:Serialization](place: Place)(body: $\RA$T) : T
\end{lstlisting}
We discuss the \lstinline{Serialization} type class in
Section~\ref{sec:serialization}.


The primitive construct for \emph{distribution} is \lstinline{at}. The invocation
\begin{lstlisting}
  val r = at(p) { work() }
\end{lstlisting}
executes the method \lstinline{work} at place \lstinline{p}, and blocks until
it terminates and returns the result. Asynchronously spawning tasks at remote places can be achieved by composing the two constructs:
\begin{lstlisting}
  at(p) { async { work() }}
\end{lstlisting}
This operation is so common that we have an semantically equivalent but optimized version with the signature
\begin{lstlisting}
  def asyncAt(place: Place)(body: $\RA$Unit) : Unit
\end{lstlisting}

Finally, \lstinline{finish} detects termination: an invocation of
\lstinline{finish} will execute its body and block until all nested invocations
of \lstinline{async} have completed. The set of \lstinline{async} invocations
that are controlled includes all recursive invocations, including all remote
ones. This makes \lstinline{finish} a powerful contribution of \apgas.

Fibonacci

SPDM

Memory: PlaceLocal, PlaceLocalRef

Place failure.

\subsection{Similarities and Differences with Futures and Actors}

Discuss future vs.\ async (returning void means no value). Future can be awaited anywhere, but must be awaited ``manually''.

finish counts (including distributed tasks!) and has no real equivalent.

Actors: unified model for concurrency and distribution.

Handling failures: Try vs Exception vs. Messages

Async at: active messages: get executed "immediately", actor messages handled one-by-one.

In the following sections, we highlight some of the points above through two
benchmarks, \kmeans clustering and unbalanced tree search.


% \input{patterns}
% Figure~\ref{fig:apgas-patterns} shows patterns.

